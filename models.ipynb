{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "FILTER_SIZE = 3\n",
    "FILTER_STRIDE = 1 \n",
    "REGULARIZER_LAMBDA = 0.01\n",
    "TRAIN_VAL_SPLIT=0.1\n",
    "TEST_SPLIT_VAL = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"../data/disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48117 files belonging to 56 classes.\n",
      "Using 43306 files for training.\n",
      "Using 4811 files for validation.\n",
      "Using 2432 files for validation.\n",
      "Using 2400 files for testing.\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = tf.keras.utils.image_dataset_from_directory(data_path, label_mode=\"int\", batch_size=BATCH_SIZE, seed=100, validation_split=TRAIN_VAL_SPLIT, subset=\"both\")\n",
    "boundary = math.floor(TEST_SPLIT_VAL*val_data.cardinality().numpy())\n",
    "test_data = val_data.take(boundary)\n",
    "val_data = val_data.skip(boundary)\n",
    "print(f\"Using {val_data.cardinality().numpy()*BATCH_SIZE} files for validation.\")\n",
    "print(f\"Using {test_data.cardinality().numpy()*BATCH_SIZE} files for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 99\n",
    "# splitfolders.ratio(\"../data/disease\", output=\"../data/split\", seed=SEED, ratio=(0.9, 0.05, 0.05), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43281 images belonging to 56 classes.\n",
      "Found 2455 images belonging to 56 classes.\n",
      "Found 2380 images belonging to 56 classes.\n"
     ]
    }
   ],
   "source": [
    "train_augment = ImageDataGenerator(\n",
    "rotation_range=360, fill_mode=\"wrap\", width_shift_range = 0.1, height_shift_range = 0.1, brightness_range=(0.5, 1.5), zoom_range=0.2, horizontal_flip=True, vertical_flip=True, rescale=1./255\n",
    ") \n",
    "val_test_augment = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_augment.flow_from_directory(directory=\"../data/split/train\", batch_size=32, target_size=(256, 256), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)\n",
    "test_generator = val_test_augment.flow_from_directory(directory=\"../data/split/test\", batch_size=1, target_size=(256, 256), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)\n",
    "val_generator = val_test_augment.flow_from_directory(directory=\"../data/split/val\", batch_size=32, target_size=(256, 256), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Cherry___Powdery_mildew', 'Cherry___healthy', 'Citrus___Black_spot', 'Citrus___Canker', 'Citrus___Greening', 'Citrus___Healthy', 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 'Corn___Common_rust', 'Corn___Northern_Leaf_Blight', 'Corn___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Rice___BrownSpot', 'Rice___Healthy', 'Rice___Hispa', 'Rice___LeafBlast', 'Soybean___Bacterial_Pustule', 'Soybean___Frogeye_Leaf_Spot', 'Soybean___Healthy', 'Soybean___Rust', 'Soybean___Sudden_Death_Syndrome', 'Soybean___Target_Leaf_Spot', 'Soybean___Yellow_Mosaic', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Sugarcane___Healthy', 'Sugarcane___Mosaic', 'Sugarcane___Red_rot', 'Sugarcane___Rust', 'Sugarcane___Yellow', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy', 'Wheat___Leaf_rust', 'Wheat___Stem_rust', 'Wheat___healthy'])\n"
     ]
    }
   ],
   "source": [
    "print((train_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_augment_2 = ImageDataGenerator(\n",
    "# rotation_range=360, fill_mode=\"wrap\", width_shift_range = 0.1, height_shift_range = 0.1, brightness_range=(0.5, 1.5), zoom_range=0.2, horizontal_flip=True, vertical_flip=True, rescale=1./255\n",
    "# ) \n",
    "# val_test_augment_2 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_generator_2 = train_augment.flow_from_directory(directory=\"../data/split2/train\", batch_size=32, target_size=(256, 256), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)\n",
    "# test_generator_2 = val_test_augment.flow_from_directory(directory=\"../data/split2/test\", batch_size=1, target_size=(256, 256), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)\n",
    "# val_generator_2 = val_test_augment.flow_from_directory(directory=\"../data/split2/val\", batch_size=32, target_size=(256, 256), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43281 images belonging to 56 classes.\n",
      "Found 2455 images belonging to 56 classes.\n",
      "Found 2380 images belonging to 56 classes.\n"
     ]
    }
   ],
   "source": [
    "mobile_train_generator = train_augment.flow_from_directory(directory=\"../data/split/train\", batch_size=32, target_size=(224, 224), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)\n",
    "mobile_test_generator = val_test_augment.flow_from_directory(directory=\"../data/split/test\", batch_size=1, target_size=(224, 224), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)\n",
    "mobile_val_generator = val_test_augment.flow_from_directory(directory=\"../data/split/val\", batch_size=32, target_size=(224, 224), color_mode=\"rgb\", class_mode=\"sparse\", seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall, Accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize = tf.keras.layers.Resizing(height=256, width=256, crop_to_aspect_ratio=True)\n",
    "# flip = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "# rotate = tf.keras.layers.RandomRotation(1) # Full 360 degree rotation\n",
    "# crop = tf.keras.layers.RandomCrop(128, 128) # Doesn't work on Mac for some reason\n",
    "# zoom = tf.keras.layers.RandomZoom(-0.2, 0.2)\n",
    "# LABEL_NAMES = train_data.class_names\n",
    "# NUM_LABELS = len(LABEL_NAMES)\n",
    "# fig, ax = plt.subplots(ncols=4, nrows=2, figsize=(32, 12))\n",
    "# train_np_iterator = train_data.as_numpy_iterator()\n",
    "# batch = train_np_iterator.next()\n",
    "# for idx, img in enumerate(batch[0][:4]):\n",
    "#     ax[0][idx].imshow(img.astype(int))\n",
    "#     ax[0][idx].title.set_text(f\"{batch[1][idx]} - {LABEL_NAMES[batch[1][idx]]}\")\n",
    "#     ax[1][idx].imshow(resize(img).numpy().astype(int))\n",
    "#     ax[1][idx].title.set_text(f\"Resized - {batch[1][idx]} - {LABEL_NAMES[batch[1][idx]]}\")\n",
    "#     ax[1][idx].imshow(rotate(img).numpy().astype(int))\n",
    "#     ax[1][idx].title.set_text(f\"Cropped - {batch[1][idx]} - {LABEL_NAMES[batch[1][idx]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model - Initial testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = Sequential()\n",
    "baseline_model.add(Conv2D(1, (3, 3), 1, activation=\"relu\", padding=\"same\", input_shape=(256, 256, 3)))\n",
    "baseline_model.add(MaxPooling2D(pool_size=(2, 2), strides=2)) # 128\n",
    "baseline_model.add(Flatten())\n",
    "baseline_model.add(Dense(128, activation=\"relu\"))\n",
    "baseline_model.add(Dense(56, activation=\"softmax\")) # multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.build((None, 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 1)       28        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 128, 128, 1)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               2097280   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 56)                7224      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2104532 (8.03 MB)\n",
      "Trainable params: 2104532 (8.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/n_x83b7d1_q6ljq1n9bjz9x40000gn/T/ipykernel_39437/214543348.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  baseline_hist = baseline_model.fit_generator(train_generator, epochs=20, validation_data=val_generator, callbacks=[baseline_stopper])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1353/1353 [==============================] - 523s 386ms/step - loss: 3.3430 - accuracy: 0.1820 - val_loss: 6.2175 - val_accuracy: 0.1832\n",
      "Epoch 2/20\n",
      "1353/1353 [==============================] - 511s 377ms/step - loss: 14.6731 - accuracy: 0.1082 - val_loss: 26.1795 - val_accuracy: 0.1008\n",
      "Epoch 3/20\n",
      "1353/1353 [==============================] - ETA: 0s - loss: 26.9482 - accuracy: 0.1018Restoring model weights from the end of the best epoch: 1.\n",
      "1353/1353 [==============================] - 509s 376ms/step - loss: 26.9482 - accuracy: 0.1018 - val_loss: 24.6842 - val_accuracy: 0.1113\n",
      "Epoch 3: early stopping\n"
     ]
    }
   ],
   "source": [
    "baseline_hist = baseline_model.fit_generator(train_generator, epochs=20, validation_data=val_generator, callbacks=[baseline_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2455/2455 [==============================] - 16s 6ms/step - loss: 6.2231 - accuracy: 0.1882\n",
      "[6.223121643066406, 0.188187375664711]\n"
     ]
    }
   ],
   "source": [
    "print(baseline_model.evaluate(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **So, accuracy for baseline model is 18.9%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobile Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobile_net(hp):\n",
    "    url = \"https://www.kaggle.com/models/google/mobilenet-v3/frameworks/TensorFlow2/variations/large-075-224-feature-vector/versions/1\"\n",
    "    base_mobile_model = hub.KerasLayer(url)\n",
    "    base_mobile_model.trainable = False\n",
    "    new_mobile_model = Sequential([\n",
    "        base_mobile_model,\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(56, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    new_mobile_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(learning_rate=hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-1, step=10, sampling=\"log\")), metrics=[\"accuracy\"])\n",
    "    return new_mobile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./models/final/Mobile_Net_Final/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_mobile_net = RandomSearch(\n",
    "    mobile_net,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10000, # just default to max number of configs\n",
    "    executions_per_trial=1,\n",
    "    directory=\"./models/final\",\n",
    "    project_name=\"Mobile_Net_Final\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 1\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': 10, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner_mobile_net.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_mobile_net.search(mobile_train_generator,callbacks=[baseline_stopper], epochs=27, validation_data=mobile_val_generator) # Can use baseline_stopper for stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adam', 'learning_rate': 0.0001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    }
   ],
   "source": [
    "mobile_hps = tuner_mobile_net.oracle.get_best_trials(num_trials=1)[0].hyperparameters\n",
    "final_mobile_net = mobile_net(mobile_hps)\n",
    "print(final_mobile_net.optimizer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "1353/1353 [==============================] - 484s 358ms/step - loss: 0.2444 - accuracy: 0.9124 - val_loss: 0.2600 - val_accuracy: 0.9067\n",
      "Epoch 2/27\n",
      "1353/1353 [==============================] - 552s 408ms/step - loss: 0.2314 - accuracy: 0.9175 - val_loss: 0.2513 - val_accuracy: 0.9164\n",
      "Epoch 3/27\n",
      "1353/1353 [==============================] - 522s 386ms/step - loss: 0.2252 - accuracy: 0.9193 - val_loss: 0.2536 - val_accuracy: 0.9101\n",
      "Epoch 4/27\n",
      "1353/1353 [==============================] - 457s 338ms/step - loss: 0.2207 - accuracy: 0.9204 - val_loss: 0.2465 - val_accuracy: 0.9139\n",
      "Epoch 5/27\n",
      "1353/1353 [==============================] - 447s 331ms/step - loss: 0.2162 - accuracy: 0.9220 - val_loss: 0.2324 - val_accuracy: 0.9164\n",
      "Epoch 6/27\n",
      "1353/1353 [==============================] - 441s 326ms/step - loss: 0.2103 - accuracy: 0.9226 - val_loss: 0.2348 - val_accuracy: 0.9197\n",
      "Epoch 7/27\n",
      "1353/1353 [==============================] - 446s 330ms/step - loss: 0.2050 - accuracy: 0.9255 - val_loss: 0.2314 - val_accuracy: 0.9155\n",
      "Epoch 8/27\n",
      "1353/1353 [==============================] - 483s 357ms/step - loss: 0.2027 - accuracy: 0.9258 - val_loss: 0.2358 - val_accuracy: 0.9164\n",
      "Epoch 9/27\n",
      "1353/1353 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9260Restoring model weights from the end of the best epoch: 7.\n",
      "1353/1353 [==============================] - 568s 420ms/step - loss: 0.2005 - accuracy: 0.9260 - val_loss: 0.2370 - val_accuracy: 0.9126\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c4547190>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mobile_net.fit(mobile_train_generator, epochs=27, callbacks=[baseline_stopper], validation_data=mobile_val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2455/2455 [==============================] - 82s 33ms/step - loss: 0.2501 - accuracy: 0.9096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25006043910980225, 0.9095723032951355]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mobile_net.evaluate(mobile_test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mobile_net.save(\"./models/final/SAVED_MODELS/Mobile_Net/Mobile_Net.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/final/SAVED_MODELS/Mobile_Net/SavedModelFormat/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/final/SAVED_MODELS/Mobile_Net/SavedModelFormat/assets\n"
     ]
    }
   ],
   "source": [
    "final_mobile_net.save(\"./models/final/SAVED_MODELS/Mobile_Net/SavedModelFormat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tejas/miniconda3/envs/dl/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "final_mobile_net.save(\"./models/final/SAVED_MODELS/Mobile_Net/Mobile_Net.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **So, accuracy for MobileNet model is 91%**\n",
    "In my Rise video, I said 93%. The difference in accuracy is because I continued work on my Rise project after submission and trained the model again after submitting, so there was a slight change in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def efficient_net(hp):\n",
    "    url = \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet21k-m-feature-vector/versions/2\"\n",
    "    base_efficientnet_model = hub.KerasLayer(url, input_shape=(256, 256, 3))\n",
    "    base_efficientnet_model.trainable = False\n",
    "    new_efficientnet_model = Sequential([\n",
    "        base_efficientnet_model,\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(56, activation=\"softmax\")\n",
    "    ])\n",
    "    new_efficientnet_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(learning_rate=hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-1, step=10, sampling=\"log\")), metrics=[\"accuracy\"])\n",
    "    return new_efficientnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_efficient_net = RandomSearch(\n",
    "    efficient_net,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10000, # just default to max number of configs\n",
    "    executions_per_trial=1,\n",
    "    directory=\"./models/final\",\n",
    "    project_name=\"Efficient_Net_Final\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 28m 48s]\n",
      "val_accuracy: 0.8415966629981995\n",
      "\n",
      "Best val_accuracy So Far: 0.9474790096282959\n",
      "Total elapsed time: 07h 13m 33s\n"
     ]
    }
   ],
   "source": [
    "tuner_efficient_net.search(train_generator, callbacks=[efficient_stopper], epochs=27, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adam', 'learning_rate': 0.0001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    }
   ],
   "source": [
    "efficient_hps = tuner_efficient_net.oracle.get_best_trials(num_trials=1)[0].hyperparameters\n",
    "final_efficient_net = efficient_net(efficient_hps)\n",
    "print(final_efficient_net.optimizer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "1353/1353 [==============================] - 750s 541ms/step - loss: 0.8302 - accuracy: 0.7713 - val_loss: 0.3165 - val_accuracy: 0.8962\n",
      "Epoch 2/27\n",
      "1353/1353 [==============================] - 680s 503ms/step - loss: 0.2592 - accuracy: 0.9113 - val_loss: 0.2141 - val_accuracy: 0.9248\n",
      "Epoch 3/27\n",
      "1353/1353 [==============================] - 572s 422ms/step - loss: 0.1988 - accuracy: 0.9315 - val_loss: 0.1968 - val_accuracy: 0.9303\n",
      "Epoch 4/27\n",
      "1353/1353 [==============================] - 563s 416ms/step - loss: 0.1705 - accuracy: 0.9414 - val_loss: 0.1871 - val_accuracy: 0.9307\n",
      "Epoch 5/27\n",
      "1353/1353 [==============================] - 575s 425ms/step - loss: 0.1548 - accuracy: 0.9442 - val_loss: 0.1510 - val_accuracy: 0.9433\n",
      "Epoch 6/27\n",
      "1353/1353 [==============================] - 564s 417ms/step - loss: 0.1412 - accuracy: 0.9500 - val_loss: 0.1601 - val_accuracy: 0.9433\n",
      "Epoch 7/27\n",
      "1353/1353 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9525Restoring model weights from the end of the best epoch: 5.\n",
      "1353/1353 [==============================] - 566s 418ms/step - loss: 0.1329 - accuracy: 0.9525 - val_loss: 0.1630 - val_accuracy: 0.9466\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x6894a85b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_efficient_net.fit(train_generator, epochs=27, callbacks=[efficient_stopper], validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2455/2455 [==============================] - 201s 82ms/step - loss: 0.1488 - accuracy: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14879626035690308, 0.9494908452033997]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_efficient_net.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_efficient_net.save(\"./models/final/SAVED_MODELS/Efficient_Net/Efficient_Net.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/final/SAVED_MODELS/Efficient_Net/SavedModelFormat/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/final/SAVED_MODELS/Efficient_Net/SavedModelFormat/assets\n"
     ]
    }
   ],
   "source": [
    "final_efficient_net.save(\"./models/final/SAVED_MODELS/Efficient_Net/SavedModelFormat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tejas/miniconda3/envs/dl/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "final_efficient_net.save(\"./models/final/SAVED_MODELS/Efficient_Net/Efficient_Net.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **So, accuracy for EfficientNet model is 94.9%**\n",
    "In my Rise video, I said 96%. The difference in accuracy is because I continued work on my Rise project after submission and trained the model again after submitting, so there was a slight change in accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
